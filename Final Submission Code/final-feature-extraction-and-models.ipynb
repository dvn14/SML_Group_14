{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from random import choice, sample, shuffle\n",
    "import math\n",
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:32<00:00, 617.66it/s] \n"
     ]
    }
   ],
   "source": [
    "with open(\"train.txt\") as file :\n",
    "    all_lines = file.read().splitlines()\n",
    "\n",
    "followers_numb = Counter()\n",
    "followers_list = defaultdict(list)\n",
    "following_numb = Counter()\n",
    "following_list = defaultdict(list)\n",
    "\n",
    "all_nodes = []\n",
    "source_nodes = []\n",
    "\n",
    "for line in tqdm(all_lines) :\n",
    "    nodes = line.split(\"\\t\")\n",
    "    source, sinks = nodes[0], nodes[1:]\n",
    "    sinks = list(map(int, sinks))\n",
    "    source = int(source)\n",
    "    while source in sinks: sinks.remove(source)\n",
    "        \n",
    "    following_list[source] = sinks\n",
    "    following_numb[source] = len(sinks)\n",
    "    \n",
    "    for sink in sinks :\n",
    "        followers_list[sink].append(source)\n",
    "        followers_numb[sink] = len(followers_list[sink])\n",
    "    \n",
    "    all_nodes.append(source)\n",
    "    all_nodes.extend(sinks)\n",
    "    \n",
    "all_nodes = list(set(all_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats about `train.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines in train.txt:  20000\n",
      "Total edges in train.txt:  24004344\n",
      "Total distinct nodes 4867136\n",
      "Size of Source nodes:  20000\n",
      "Size of null entries:  430\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "null = 0\n",
    "\n",
    "for node in following_numb :\n",
    "    if following_numb[node] == 0 :\n",
    "        null += 1\n",
    "    else :\n",
    "        i += following_numb[node]\n",
    "\n",
    "print(\"Total lines in train.txt: \", len(all_lines))\n",
    "print(\"Total edges in train.txt: \", i)\n",
    "print(\"Total distinct nodes\", len(all_nodes))\n",
    "print(\"Size of Source nodes: \", len(edges))\n",
    "print(\"Size of null entries: \", null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loading Reduced Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Positive Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   source     sink\n",
      "0           0   765601  2006214\n",
      "1           1  1750842  4144037\n",
      "2           2  1973082   229375\n",
      "3           3  3361377  1542427\n",
      "4           4  4230144  1246469\n",
      "(20001, 3)\n",
      "20001 20001\n"
     ]
    }
   ],
   "source": [
    "pos_subPair = pd.read_csv('pos_subPair.csv', sep=\",\")\n",
    "print(pos_subPair.head())\n",
    "print(pos_subPair.shape)\n",
    "pos_train_source_list = list(pos_subPair['source'])\n",
    "pos_train_sink_list = list(pos_subPair['sink'])\n",
    "\n",
    "print(len(pos_train_source_list), len(pos_train_sink_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Negative Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   source     sink\n",
      "0           0   493062     9330\n",
      "1           1  4618437  2311748\n",
      "2           2  4391648  1548304\n",
      "3           3  1628298  1893139\n",
      "4           4  1807730  4719681\n",
      "(20001, 3)\n",
      "20001 20001\n"
     ]
    }
   ],
   "source": [
    "neg_subPair = pd.read_csv('neg_subPair.csv', sep=\",\")\n",
    "neg_subPair = neg_subPair.rename(columns = {'0': 'source', '1': 'sink'}, inplace = False)\n",
    "print(neg_subPair.head())\n",
    "print(neg_subPair.shape)\n",
    "neg_train_source_list = list(neg_subPair['source'])\n",
    "neg_train_sink_list = list(neg_subPair['sink'])\n",
    "\n",
    "print(len(neg_train_source_list), len(neg_train_sink_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature Engineering\n",
    "\n",
    "#### 4.1 Common Friends\n",
    "\n",
    "- **x1** - source → c → sink\n",
    "- **x2** - source → c ← sink\n",
    "- **x3** - source ← c → sink\n",
    "- **x4** - source ← c ← sink\n",
    "- **x5** - Jaccard's coeffcient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_common_friends (source, sink, following_list, followers_list) :\n",
    "    \n",
    "    source_following, source_followers, sink_following, sink_followers = [], [], [], []\n",
    "    x1, x2, x3, x4, x5 = 0, 0, 0, 0, 0\n",
    "    \n",
    "    if source in following_list :\n",
    "        source_following = following_list[source]\n",
    "        \n",
    "    if source in followers_list :\n",
    "        source_followers = followers_list[source]\n",
    "    \n",
    "    if sink in following_list :\n",
    "        sink_following = following_list[sink]\n",
    "        \n",
    "    if sink in followers_list :\n",
    "        sink_followers = followers_list[sink]\n",
    "    \n",
    "    if source_following != [] and sink_followers != [] :\n",
    "        x1 = len(set(source_following).intersection(sink_followers))\n",
    "        \n",
    "    if source_following != [] and sink_following != [] :\n",
    "        x2 = len(set(source_following).intersection(sink_following))\n",
    "        \n",
    "    if source_followers != [] and sink_followers != [] :\n",
    "        x3 = len(set(source_followers).intersection(sink_followers))\n",
    "    \n",
    "    if source_followers != [] and sink_following != [] :\n",
    "        x4 = len(set(source_followers).intersection(sink_following))\n",
    "        \n",
    "    related_source = set(source_following).union(source_followers)\n",
    "    related_sink = set(sink_following).union(sink_followers)\n",
    "    common_nodes = list(set(related_source).intersection(related_sink))\n",
    "    related_both = len(set(related_source).union(related_sink))\n",
    "#     if related_both != 0:\n",
    "#         x5 = len(common_nodes)/related_both\n",
    "    x5=len(common_nodes)\n",
    "        \n",
    "    return x1, x2, x3, x4, x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 0, 57, 0, 0.0005899705014749262, 60)\n",
      "(0, 0, 0, 0, 0.0, 0)\n"
     ]
    }
   ],
   "source": [
    "test = gen_common_friends(765601, 2006214, following_list, followers_list)\n",
    "print(test)\n",
    "test = gen_common_friends(4391648, 1548304, following_list, followers_list)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Node stats\n",
    "\n",
    "- **x6** - Number following (Source).\n",
    "- **x7** - Number following (Sink).\n",
    "- **x8** - Number of followers (Source).\n",
    "- **x9** - Number of followers (Sink)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_node_stats (source, sink, following_numb, followers_numb) :\n",
    "    x6, x7, x8, x9 = 0, 0, 0, 0\n",
    "    x6 = following_numb[source]\n",
    "    x9 = followers_numb[sink]\n",
    "    \n",
    "    return x6, x9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Generating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20001/20001 [09:47<00:00, 34.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pos_train_features = []\n",
    "\n",
    "for i in tqdm(range(len(pos_train_source_list))) :\n",
    "    source = pos_train_source_list[i]\n",
    "    sink = pos_train_sink_list[i]\n",
    "    \n",
    "    x1, x2, x3, x4, x5 = gen_common_friends(source, sink, following_list, followers_list)\n",
    "    #feat2 = gen_node_stats(source, sink, following_numb, followers_numb)\n",
    "    \n",
    "    pos_train_features.append([x1, x2, x3, x4, x5, 1])\n",
    "    \n",
    "print(len(pos_train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20001/20001 [00:00<00:00, 400014.66it/s]\n"
     ]
    }
   ],
   "source": [
    "pos_train_features2=[]\n",
    "for i in tqdm(range(len(pos_train_source_list))) :\n",
    "    source = pos_train_source_list[i]\n",
    "    sink = pos_train_sink_list[i]\n",
    "    x6, x9= gen_node_stats (source, sink, following_numb, followers_numb) \n",
    "    \n",
    "    pos_train_features2.append([x6,x9])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train_features_total=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_train_features_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training Model - First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 32001 instances. Test set has 8001 instances.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=90051)\n",
    "print(\"Training set has {} instances. Test set has {} instances.\".format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [ -1.19244575   0.51252288   0.14435657   0.29479233  -0.03321564\n",
      " -24.83857673]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(penalty='none')\n",
    "model.fit(X, y)\n",
    "w_sklearn = np.r_[model.intercept_, model.coef_.squeeze()]\n",
    "print(\"Weights: {}\".format(w_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Loading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   Source     Sink\n",
      "0   1  3563811  3600160\n",
      "1   2  2052043  1401960\n",
      "2   3  4517994  1690636\n",
      "3   4  1660006  4349447\n",
      "4   5   581111  1882617\n",
      "(2000, 3)\n"
     ]
    }
   ],
   "source": [
    "testData = pd.read_csv('test-public.txt', sep=\"\\t\")\n",
    "testData_ids = list(testData['Id'])\n",
    "test_source_list = list(testData['Source'])\n",
    "test_sink_list = list(testData['Sink'])\n",
    "print(testData.head())\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1344.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "      x1  x2  x3  x4  x5   x6  x7\n",
      "0      0   0   0   0   0   21  29\n",
      "1      0   0   0   0   0   71   9\n",
      "2      2   0   2   0   3  205  17\n",
      "3      2   0   2   0   2  506  36\n",
      "4      0   0   0   0   0   18  46\n",
      "...   ..  ..  ..  ..  ..  ...  ..\n",
      "1995   0   0   0   0   0   53   2\n",
      "1996   0   0   1   0   1   95  41\n",
      "1997   0   0   0   0   0   27   2\n",
      "1998   0   0   0   0   0   56   3\n",
      "1999   0   0   0   0   0  244   2\n",
      "\n",
      "[2000 rows x 7 columns]\n",
      "(2000, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_features = []\n",
    "\n",
    "for i in tqdm(range(len(test_source_list))) :\n",
    "    source = test_source_list[i]\n",
    "    sink = test_sink_list[i]\n",
    "    \n",
    "    x1, x2, x3, x4, x5, x6, x9 = gen_common_friends2(source, sink, following_list, followers_list,following_numb, followers_numb)\n",
    "    #feat2 = gen_node_stats(source, sink, following_numb, followers_numb)\n",
    "    \n",
    "    test_features.append([x1, x2, x3, x4, x5,x6,x9])\n",
    "    \n",
    "print(len(test_features))\n",
    "\n",
    "test_features = pd.DataFrame(test_features, columns = ['x1', 'x2', 'x3', 'x4', 'x5','x6','x7'])\n",
    "print(test_features)\n",
    "print(test_features.shape)\n",
    "test_features.to_csv('test-features-new.csv', sep=\",\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Stage Feature: Adamic-Adar Feature\n",
    "\n",
    "**x8** adamic-adar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_adamic_adar (source, sink, following_list, followers_list) :\n",
    "    \n",
    "    source_following, source_followers, sink_following, sink_followers = [], [], [], []\n",
    "    \n",
    "    if source in following_list :\n",
    "        source_following = following_list[source]\n",
    "        \n",
    "    if source in followers_list :\n",
    "        source_followers = followers_list[source]\n",
    "    \n",
    "    if sink in following_list :\n",
    "        sink_following = following_list[sink]\n",
    "        \n",
    "    if sink in followers_list :\n",
    "        sink_followers = followers_list[sink]\n",
    "    \n",
    "    related_source = set(source_following).union(source_followers)\n",
    "    related_sink = set(sink_following).union(sink_followers)\n",
    "    common_nodes = list(set(related_source).intersection(related_sink))\n",
    "#     if related_both != 0:\n",
    "#         x5 = len(common_nodes)/related_both\n",
    "    \n",
    "    x6=0\n",
    "    for common_node in common_nodes:\n",
    "        num_follow_commonfriend=0\n",
    "        if common_node in following_list:\n",
    "            num_follow_commonfriend+=len(following_list[common_node])\n",
    "        if common_node in followers_list:\n",
    "            num_follow_commonfriend+=len(followers_list[common_node])\n",
    "        if(num_follow_commonfriend!=0):\n",
    "            x6+=1/math.log(num_follow_commonfriend)\n",
    "        \n",
    "    return x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20001/20001 [04:58<00:00, 67.11it/s] \n"
     ]
    }
   ],
   "source": [
    "Admaic_Adar_features = []\n",
    "\n",
    "for i in tqdm(range(len(pos_train_source_list))) :\n",
    "    source = pos_train_source_list[i]\n",
    "    sink = pos_train_sink_list[i]\n",
    "    \n",
    "    x8 = gen_adamic_adar(source, sink, following_list, followers_list)\n",
    "    #feat2 = gen_node_stats(source, sink, following_numb, followers_numb)\n",
    "    \n",
    "    Admaic_Adar_features.append(x8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Admaic_Adar_features, columns=['x8']).to_csv('Pos-Admaic-Adar-features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20001/20001 [00:02<00:00, 7312.98it/s]\n"
     ]
    }
   ],
   "source": [
    "Admaic_Adar_features_neg = []\n",
    "\n",
    "for i in tqdm(range(len(neg_train_source_list))) :\n",
    "    source = neg_train_source_list[i]\n",
    "    sink = neg_train_sink_list[i]\n",
    "    \n",
    "    x9 = gen_adamic_adar(source, sink, following_list, followers_list)\n",
    "    #feat2 = gen_node_stats(source, sink, following_numb, followers_numb)\n",
    "    \n",
    "    Admaic_Adar_features_neg.append(x9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Admaic_Adar_features_neg, columns=['x8']).to_csv('Neg-Admaic-Adar-features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features= pd.read_csv('pos_feature_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_jaccard = pd.read_csv('pos-features-common-friends-with-JC.csv')\n",
    "pos_jaccard_feature = list(pos_jaccard['x5'])\n",
    "pos_features.insert(9, 'x9',pos_jaccard_feature,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features.insert(8, 'x8',Admaic_Adar_features,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_features= pd.read_csv('neg_feature_new.csv')\n",
    "neg_features.insert(8, 'x8',Admaic_Adar_features_neg,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_jaccard = pd.read_csv('neg-features-common-friends-with-JC.csv')\n",
    "neg_jaccard_feature = list(neg_jaccard['x5'])\n",
    "neg_features.insert(9, 'x9',neg_jaccard_feature,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2285.71it/s]\n"
     ]
    }
   ],
   "source": [
    "Admaic_Adar_features_test = []\n",
    "\n",
    "for i in tqdm(range(len(test_source_list))) :\n",
    "    source = test_source_list[i]\n",
    "    sink = test_sink_list[i]\n",
    "    \n",
    "    x10 = gen_adamic_adar(source, sink, following_list, followers_list)\n",
    "    #feat2 = gen_node_stats(source, sink, following_numb, followers_numb)\n",
    "    \n",
    "    Admaic_Adar_features_test.append(x10)\n",
    "test_features = pd.read_csv('test-features-new.csv')\n",
    "test_features.insert(7,'x8',Admaic_Adar_features_test,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_csv('test-features-new.csv')\n",
    "test_features.insert(7,'x8',Admaic_Adar_features_test,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_jacc = pd.read_csv('test-features-common-friends-with-JC.csv')\n",
    "test_jacc_feature=list(test_jacc['x5'])\n",
    "test_features.insert(8,'x9',test_jacc_feature,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>205</td>\n",
       "      <td>17</td>\n",
       "      <td>0.459422</td>\n",
       "      <td>0.011152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>506</td>\n",
       "      <td>36</td>\n",
       "      <td>0.178376</td>\n",
       "      <td>0.003670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>46</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>41</td>\n",
       "      <td>0.100383</td>\n",
       "      <td>0.006061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1  x2  x3  x4  x5   x6  x7        x8        x9\n",
       "0      0   0   0   0   0   21  29  0.000000  0.000000\n",
       "1      0   0   0   0   0   71   9  0.000000  0.000000\n",
       "2      2   0   2   0   3  205  17  0.459422  0.011152\n",
       "3      2   0   2   0   2  506  36  0.178376  0.003670\n",
       "4      0   0   0   0   0   18  46  0.000000  0.000000\n",
       "...   ..  ..  ..  ..  ..  ...  ..       ...       ...\n",
       "1995   0   0   0   0   0   53   2  0.000000  0.000000\n",
       "1996   0   0   1   0   1   95  41  0.100383  0.006061\n",
       "1997   0   0   0   0   0   27   2  0.000000  0.000000\n",
       "1998   0   0   0   0   0   56   3  0.000000  0.000000\n",
       "1999   0   0   0   0   0  244   2  0.000000  0.000000\n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Stage: Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **x1** - source → c → sink\n",
    "- **x2** - source → c ← sink\n",
    "- **x3** - source ← c → sink\n",
    "- **x4** - source ← c ← sink\n",
    "- **x5** - total common friends\n",
    "- **x6** - number of people source following\n",
    "- **x7** - number of people followed sink\n",
    "- **x8** - Adamic Adar\n",
    "- **x9** - Jaccard Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features.to_csv('Pos_Total_Feature.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_features.to_csv('Neg_Total_Feature.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.to_csv('Test_Total_Feature.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **x10** - Hub Depressed\n",
    "- **x11** - SI\n",
    "- **x12** - SC\n",
    "- **x13** - HP\n",
    "- **x14** - PD\n",
    "- **x15** - RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_common_friends3 (source, sink, following_list, followers_list) :\n",
    "    \n",
    "    source_following, source_followers, sink_following, sink_followers = [], [], [], []\n",
    "    HD,HP,SI,SC,LHN,RA = 0, 0, 0, 0,0,0\n",
    "    \n",
    "    if source in following_list :\n",
    "        source_following = following_list[source]\n",
    "        \n",
    "    if source in followers_list:\n",
    "        source_followers = followers_list[source]\n",
    "    \n",
    "    if sink in following_list:\n",
    "        sink_following = following_list[sink]\n",
    "        \n",
    "    if sink in followers_list:\n",
    "        sink_followers = followers_list[sink]\n",
    "        \n",
    "    related_source = set(source_following).union(source_followers)\n",
    "    related_sink = set(sink_following).union(sink_followers)\n",
    "    common_nodes = list(set(related_source).intersection(related_sink))\n",
    "    related_both = len(set(related_source).union(related_sink))\n",
    "#     if related_both != 0:\n",
    "#         x5 = len(common_nodes)/related_both\n",
    "    HD = len(common_nodes)/ max(len(related_source),len(related_sink))\n",
    "    HP = len(common_nodes)/ min(len(related_source),len(related_sink))\n",
    "    SC = len(common_nodes)/ (math.sqrt(len(related_source)*len(related_sink)))\n",
    "    SI = len(common_nodes)/(len(related_source)+len(related_sink))\n",
    "    LHN = len(common_nodes)/(len(related_source)*len(related_sink))\n",
    "    \n",
    "        \n",
    "    return HD,HP,SC,SI,LHN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20001/20001 [08:00<00:00, 41.64it/s]\n"
     ]
    }
   ],
   "source": [
    "HDlist=[]\n",
    "HPlist=[]\n",
    "SClist=[]\n",
    "SIlist=[]\n",
    "LHNlist=[]\n",
    "for i in tqdm(range(len(pos_train_source_list))) :\n",
    "    source = pos_train_source_list[i]\n",
    "    sink = pos_train_sink_list[i]\n",
    "    \n",
    "    HD,HP,SC,SI,LHN = gen_common_friends3(source, sink, following_list, followers_list)\n",
    "    #feat2 = gen_node_stats(source, sink, following_numb, followers_numb)\n",
    "    \n",
    "    HDlist.append(HD)\n",
    "    HPlist.append(HP)\n",
    "    SClist.append(SC)\n",
    "    SIlist.append(SI)\n",
    "    LHNlist.append(LHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pos_additional_features).to_csv('pos_additional_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_additional_features.insert(8,'LHN',LHNlist,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20001/20001 [00:04<00:00, 4705.01it/s]\n"
     ]
    }
   ],
   "source": [
    "HDlistneg=[]\n",
    "HPlistneg=[]\n",
    "SClistneg=[]\n",
    "SIlistneg=[]\n",
    "LHNlistneg=[]\n",
    "for i in tqdm(range(len(neg_train_source_list))) :\n",
    "    source = neg_train_source_list[i]\n",
    "    sink = neg_train_sink_list[i]\n",
    "    \n",
    "    HD,HP,SC,SI,LHN = gen_common_friends3(source, sink, following_list, followers_list)\n",
    "    #feat2 = gen_node_stats(source, sink, following_numb, followers_numb)\n",
    "    \n",
    "    HDlistneg.append(HD)\n",
    "    HPlistneg.append(HP)\n",
    "    SClistneg.append(SC)\n",
    "    SIlistneg.append(SI)\n",
    "    LHNlistneg.append(LHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_additional_features=pd.read_csv('Neg_Total_Feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_additional_features=neg_additional_features.drop(columns=['HD','LHN','SI','SC','HP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_additional_features.insert(7,'HD',HDlistneg,True)\n",
    "neg_additional_features.insert(7,'LHN',LHNlistneg,True)\n",
    "neg_additional_features.insert(7,'SI',SIlistneg,True)\n",
    "neg_additional_features.insert(7,'SC',SClistneg,True)\n",
    "neg_additional_features.insert(7,'HP',HPlistneg,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(neg_additional_features).to_csv('neg_additional_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:01<00:00, 1615.51it/s]\n"
     ]
    }
   ],
   "source": [
    "HDlisttest=[]\n",
    "HPlisttest=[]\n",
    "SClisttest=[]\n",
    "SIlisttest=[]\n",
    "LHNlisttest=[]\n",
    "for i in tqdm(range(len(test_source_list))) :\n",
    "    source = test_source_list[i]\n",
    "    sink = test_sink_list[i]\n",
    "    \n",
    "    HD,HP,SC,SI,LHN = gen_common_friends3(source, sink, following_list, followers_list)\n",
    "    #feat2 = gen_node_stats(source, sink, following_numb, followers_numb)\n",
    "    \n",
    "    HDlisttest.append(HD)\n",
    "    HPlisttest.append(HP)\n",
    "    SClisttest.append(SC)\n",
    "    SIlisttest.append(SI)\n",
    "    LHNlisttest.append(LHN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_additional_features=pd.read_csv('Test_Total_Feature.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_additional_features=test_additional_features.drop(columns=['x5','x6','x7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_additional_features.insert(6,'HD',HDlisttest,True)\n",
    "test_additional_features.insert(6,'LHN',LHNlisttest,True)\n",
    "test_additional_features.insert(6,'SI',SIlisttest,True)\n",
    "test_additional_features.insert(6,'SC',SClisttest,True)\n",
    "test_additional_features.insert(6,'HP',HPlisttest,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test_additional_features).to_csv('test_additional_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Stage Feature: Resource Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_resource_allocation (source, sink, following_list, followers_list) :\n",
    "    \n",
    "    source_following, source_followers, sink_following, sink_followers = [], [], [], []\n",
    "    \n",
    "    if source in following_list :\n",
    "        source_following = following_list[source]\n",
    "        \n",
    "    if source in followers_list :\n",
    "        source_followers = followers_list[source]\n",
    "    \n",
    "    if sink in following_list :\n",
    "        sink_following = following_list[sink]\n",
    "        \n",
    "    if sink in followers_list :\n",
    "        sink_followers = followers_list[sink]\n",
    "    \n",
    "    related_source = set(source_following).union(source_followers)\n",
    "    related_sink = set(sink_following).union(sink_followers)\n",
    "    common_nodes = list(set(related_source).intersection(related_sink))\n",
    "#     if related_both != 0:\n",
    "#         x5 = len(common_nodes)/related_both\n",
    "    \n",
    "    x6=0\n",
    "    for common_node in common_nodes:\n",
    "        num_follow_commonfriend=0\n",
    "        if common_node in following_list:\n",
    "            num_follow_commonfriend+=len(following_list[common_node])\n",
    "        if common_node in followers_list:\n",
    "            num_follow_commonfriend+=len(followers_list[common_node])\n",
    "        if(num_follow_commonfriend!=0):\n",
    "            x6+=1/(num_follow_commonfriend)\n",
    "        \n",
    "    return x6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20001/20001 [05:03<00:00, 65.80it/s] \n"
     ]
    }
   ],
   "source": [
    "Admaic_Adar_features = []\n",
    "\n",
    "for i in tqdm(range(len(pos_train_source_list))) :\n",
    "    source = pos_train_source_list[i]\n",
    "    sink = pos_train_sink_list[i]\n",
    "    \n",
    "    x8 = gen_resource_allocation(source, sink, following_list, followers_list)\n",
    "    #feat2 = gen_node_stats(source, sink, following_numb, followers_numb)\n",
    "    \n",
    "    Admaic_Adar_features.append(x8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20001/20001 [00:02<00:00, 7033.87it/s]\n"
     ]
    }
   ],
   "source": [
    "Admaic_Adar_features_neg = []\n",
    "\n",
    "for i in tqdm(range(len(neg_train_source_list))) :\n",
    "    source = neg_train_source_list[i]\n",
    "    sink = neg_train_sink_list[i]\n",
    "    \n",
    "    x9 = gen_resource_allocation(source, sink, following_list, followers_list)\n",
    "    #feat2 = gen_node_stats(source, sink, following_numb, followers_numb)\n",
    "    \n",
    "    Admaic_Adar_features_neg.append(x9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features= pd.read_csv('pos_additional_features.csv')\n",
    "pos_features.insert(8, 'ra',Admaic_Adar_features,True)\n",
    "neg_features= pd.read_csv('neg_additional_features.csv')\n",
    "neg_features.insert(8, 'ra',Admaic_Adar_features_neg,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 2463.06it/s]\n"
     ]
    }
   ],
   "source": [
    "Admaic_Adar_features_test = []\n",
    "\n",
    "for i in tqdm(range(len(test_source_list))) :\n",
    "    source = test_source_list[i]\n",
    "    sink = test_sink_list[i]\n",
    "    \n",
    "    x10 = gen_resource_allocation(source, sink, following_list, followers_list)\n",
    "    #feat2 = gen_node_stats(source, sink, following_numb, followers_numb)\n",
    "    \n",
    "    Admaic_Adar_features_test.append(x10)\n",
    "test_features = pd.read_csv('test_additional_features.csv')\n",
    "test_features.insert(7,'ra',Admaic_Adar_features_test,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features.to_csv('pos_total_ra.csv')\n",
    "neg_features.to_csv('neg_total_ra.csv')\n",
    "test_features.to_csv('test_total_ra.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Selection Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final training model used features:\n",
    "- **x1** - source → c → sink\n",
    "- **x2** - source → c ← sink\n",
    "- **x3** - source ← c → sink\n",
    "- **x4** - source ← c ← sink\n",
    "- **x8** - Adamic Adar\n",
    "- **ra** - resource allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_feature=pd.read_csv('pos_total_ra.csv')\n",
    "neg_feature=pd.read_csv('neg_total_ra.csv')\n",
    "train=pd.concat([pos_feature,neg_feature])\n",
    "train1 = train.sample(frac=1).reset_index(drop=True)\n",
    "x_test=pd.read_csv('test_total_ra.csv')\n",
    "features = ['x1','x2','x3','x4','ra','x8']\n",
    "x_train=train1[features].values\n",
    "y_train=train1['y'].values\n",
    "x_test=x_test[features].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 =LogisticRegression()\n",
    "model0.fit(x_train, y_train)\n",
    "pred = model0.predict_proba(x_test)[:, 1].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = SVC(kernel='linear', probability=True)\n",
    "preds1 = model1.fit(train_x,train_y)\n",
    "prediction1 = model1.predict_proba(x_test)[:, 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = [i for i in range(1,2001)]\n",
    "submission = pd.DataFrame({'Id':id, 'Predicted':prediction1})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
