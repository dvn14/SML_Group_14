{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devin's Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from random import choice, sample, shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:27<00:00, 728.90it/s] \n"
     ]
    }
   ],
   "source": [
    "with open(\"train.txt\") as file :\n",
    "    all_lines = file.read().splitlines()\n",
    "\n",
    "followers_numb = Counter()\n",
    "followers_list = defaultdict(list)\n",
    "following_numb = Counter()\n",
    "following_list = defaultdict(list)\n",
    "\n",
    "all_nodes = []\n",
    "source_nodes = []\n",
    "\n",
    "for line in tqdm(all_lines) :\n",
    "    nodes = line.split(\"\\t\")\n",
    "    source, sinks = nodes[0], nodes[1:]\n",
    "    sinks = list(map(int, sinks))\n",
    "    source = int(source)\n",
    "    while source in sinks: sinks.remove(source)\n",
    "        \n",
    "    following_list[source] = sinks\n",
    "    following_numb[source] = len(sinks)\n",
    "    \n",
    "    for sink in sinks :\n",
    "        followers_list[sink].append(source)\n",
    "        followers_numb[sink] = len(followers_list[sink])\n",
    "    \n",
    "    all_nodes.append(source)\n",
    "    all_nodes.extend(sinks)\n",
    "    \n",
    "all_nodes = list(set(all_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats about `train.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines in train.txt:  20000\n",
      "Total edges in train.txt:  24004344\n",
      "Total distinct nodes 4867136\n",
      "Size of Source nodes:  20000\n",
      "Size of null entries:  430\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "null = 0\n",
    "\n",
    "for node in following_numb :\n",
    "    if following_numb[node] == 0 :\n",
    "        null += 1\n",
    "    else :\n",
    "        i += following_numb[node]\n",
    "\n",
    "print(\"Total lines in train.txt: \", len(all_lines))\n",
    "print(\"Total edges in train.txt: \", i)\n",
    "print(\"Total distinct nodes\", len(all_nodes))\n",
    "print(\"Size of Source nodes: \", len(edges))\n",
    "print(\"Size of null entries: \", null)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Loading Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Positive Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   source     sink\n",
      "0           0   765601  2006214\n",
      "1           1  1750842  4144037\n",
      "2           2  1973082   229375\n",
      "3           3  3361377  1542427\n",
      "4           4  4230144  1246469\n",
      "(20001, 3)\n",
      "20001 20001\n"
     ]
    }
   ],
   "source": [
    "pos_subPair = pd.read_csv('pos_subPair.csv', sep=\",\")\n",
    "print(pos_subPair.head())\n",
    "print(pos_subPair.shape)\n",
    "pos_train_source_list = list(pos_subPair['source'])\n",
    "pos_train_sink_list = list(pos_subPair['sink'])\n",
    "\n",
    "print(len(pos_train_source_list), len(pos_train_sink_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Negative Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   source     sink\n",
      "0           0   493062     9330\n",
      "1           1  4618437  2311748\n",
      "2           2  4391648  1548304\n",
      "3           3  1628298  1893139\n",
      "4           4  1807730  4719681\n",
      "(20001, 3)\n",
      "20001 20001\n"
     ]
    }
   ],
   "source": [
    "neg_subPair = pd.read_csv('neg_subPair.csv', sep=\",\")\n",
    "neg_subPair = neg_subPair.rename(columns = {'0': 'source', '1': 'sink'}, inplace = False)\n",
    "print(neg_subPair.head())\n",
    "print(neg_subPair.shape)\n",
    "neg_train_source_list = list(neg_subPair['source'])\n",
    "neg_train_sink_list = list(neg_subPair['sink'])\n",
    "\n",
    "print(len(neg_train_source_list), len(neg_train_sink_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature Engineering\n",
    "\n",
    "#### 4.1 Common Friends\n",
    "\n",
    "- **x1** - source → c → sink\n",
    "- **x2** - source → c ← sink\n",
    "- **x3** - source ← c → sink\n",
    "- **x4** - source ← c ← sink\n",
    "- **x5** - Jaccard's coeffcient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_common_friends (source, sink, following_list, followers_list) :\n",
    "    \n",
    "    source_following, source_followers, sink_following, sink_followers = [], [], [], []\n",
    "    x1, x2, x3, x4, x5 = 0, 0, 0, 0, 0\n",
    "    \n",
    "    if source in following_list :\n",
    "        source_following = following_list[source]\n",
    "        \n",
    "    if source in followers_list :\n",
    "        source_followers = followers_list[source]\n",
    "    \n",
    "    if sink in following_list :\n",
    "        sink_following = following_list[sink]\n",
    "        \n",
    "    if sink in followers_list :\n",
    "        sink_followers = followers_list[sink]\n",
    "    \n",
    "    if source_following != [] and sink_followers != [] :\n",
    "        x1 = len(set(source_following).intersection(sink_followers))\n",
    "        \n",
    "    if source_following != [] and sink_following != [] :\n",
    "        x2 = len(set(source_following).intersection(sink_following))\n",
    "        \n",
    "    if source_followers != [] and sink_followers != [] :\n",
    "        x3 = len(set(source_followers).intersection(sink_followers))\n",
    "    \n",
    "    if source_followers != [] and sink_following != [] :\n",
    "        x4 = len(set(source_followers).intersection(sink_following))\n",
    "        \n",
    "    related_source = set(source_following).union(source_followers)\n",
    "    related_sink = set(sink_following).union(sink_followers)\n",
    "    common_nodes = list(set(related_source).intersection(related_sink))\n",
    "    related_both = len(set(related_source).union(related_sink))\n",
    "    if related_both != 0:\n",
    "        x5 = len(common_nodes)/related_both\n",
    "        \n",
    "    return x1, x2, x3, x4, x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 0, 57, 0, 0.0005899705014749262)\n",
      "(0, 0, 0, 0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "test = gen_common_friends(765601, 2006214, following_list, followers_list)\n",
    "print(test)\n",
    "test = gen_common_friends(4391648, 1548304, following_list, followers_list)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Node stats\n",
    "\n",
    "- **x6** - Number following (Source).\n",
    "- **x7** - Number following (Sink).\n",
    "- **x8** - Number of followers (Source).\n",
    "- **x9** - Number of followers (Sink)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_node_stats (source, sink, following_numb, followers_numb) :\n",
    "    x6, x7, x8, x9 = 0, 0, 0, 0\n",
    "    x6 = following_numb[source]\n",
    "    x7 = following_numb[sink]\n",
    "    x8 = followers_numb[source]\n",
    "    x9 = followers_numb[sink]\n",
    "    \n",
    "    return x6, x7, x8, x9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Generating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20001/20001 [15:02<00:00, 22.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pos_train_features = []\n",
    "\n",
    "for i in tqdm(range(len(pos_train_source_list))) :\n",
    "    source = pos_train_source_list[i]\n",
    "    sink = pos_train_sink_list[i]\n",
    "    \n",
    "    x1, x2, x3, x4, x5 = gen_common_friends(source, sink, following_list, followers_list)\n",
    "    #feat2 = gen_node_stats(source, sink, following_numb, followers_numb)\n",
    "    \n",
    "    pos_train_features.append([x1, x2, x3, x4, x5, 1])\n",
    "    \n",
    "print(len(pos_train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20001/20001 [00:09<00:00, 2160.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "neg_train_features = []\n",
    "\n",
    "for i in tqdm(range(len(neg_train_source_list))) :\n",
    "    source = neg_train_source_list[i]\n",
    "    sink = neg_train_sink_list[i]\n",
    "    \n",
    "    x1, x2, x3, x4, x5 = gen_common_friends(source, sink, following_list, followers_list)\n",
    "    #feat2 = gen_node_stats(source, sink, following_numb, followers_numb)\n",
    "    \n",
    "    neg_train_features.append([x1, x2, x3, x4, x5, 0])\n",
    "    \n",
    "print(len(neg_train_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20001 [[59, 0, 57, 0, 0.0005899705014749262, 1], [2, 2, 2, 2, 0.0019860973187686196, 1], [19, 0, 11, 0, 0.0009982661692849262, 1], [1, 0, 1, 0, 1.3112037112309842e-06, 1], [0, 0, 0, 0, 0.0, 1], [37, 0, 36, 0, 0.0009086561453849832, 1], [0, 0, 0, 0, 0.0, 1], [0, 0, 0, 0, 0.0, 1], [13, 0, 13, 0, 0.0016337815759708432, 1], [41, 0, 40, 0, 0.00043891107233468577, 1]]\n",
      "20001 [[1, 0, 1, 0, 0.00036603221083455345, 0], [0, 0, 0, 0, 0.0, 0], [0, 0, 0, 0, 0.0, 0], [0, 0, 0, 0, 0.0, 0], [0, 0, 0, 0, 0.0, 0], [1, 0, 0, 0, 0.008, 0], [0, 0, 0, 0, 0.0, 0], [0, 0, 0, 0, 0.0, 0], [0, 0, 0, 0, 0.0, 0], [0, 0, 0, 0, 0.0, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_train_features), pos_train_features[0:10])\n",
    "print(len(neg_train_features), neg_train_features[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40002"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features = pos_train_features.copy()\n",
    "train_features.extend(neg_train_features)\n",
    "len(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       x1  x2  x3  x4        x5  y\n",
      "0      59   0  57   0  0.000590  1\n",
      "1       2   2   2   2  0.001986  1\n",
      "2      19   0  11   0  0.000998  1\n",
      "3       1   0   1   0  0.000001  1\n",
      "4       0   0   0   0  0.000000  1\n",
      "...    ..  ..  ..  ..       ... ..\n",
      "39997   0   0   0   0  0.000000  0\n",
      "39998   0   0   0   0  0.000000  0\n",
      "39999  14   0   9   0  0.020380  0\n",
      "40000   0   0   0   0  0.000000  0\n",
      "40001   0   0   0   0  0.000000  0\n",
      "\n",
      "[40002 rows x 6 columns]\n",
      "(40002, 6)\n"
     ]
    }
   ],
   "source": [
    "train_features_df = pd.DataFrame(train_features, columns = ['x1', 'x2', 'x3', 'x4', 'x5', 'y'])\n",
    "print(train_features_df)\n",
    "print(train_features_df.shape)\n",
    "\n",
    "X = train_features_df[['x1', 'x2', 'x3', 'x4', 'x5']]\n",
    "y = train_features_df['y']\n",
    "\n",
    "train_features_df.to_csv('features-common-friends-with-JC.csv', sep=\",\", index=True, index_label = 'Id', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 32001 instances. Test set has 8001 instances.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=90051)\n",
    "print(\"Training set has {} instances. Test set has {} instances.\".format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [ -1.19244575   0.51252288   0.14435657   0.29479233  -0.03321564\n",
      " -24.83857673]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(penalty='none')\n",
    "model.fit(X, y)\n",
    "w_sklearn = np.r_[model.intercept_, model.coef_.squeeze()]\n",
    "print(\"Weights: {}\".format(w_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Loading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   Source     Sink\n",
      "0   1  3563811  3600160\n",
      "1   2  2052043  1401960\n",
      "2   3  4517994  1690636\n",
      "3   4  1660006  4349447\n",
      "4   5   581111  1882617\n",
      "(2000, 3)\n"
     ]
    }
   ],
   "source": [
    "testData = pd.read_csv('test-public.txt', sep=\"\\t\")\n",
    "testData_ids = list(testData['Id'])\n",
    "test_source_list = list(testData['Source'])\n",
    "test_sink_list = list(testData['Sink'])\n",
    "print(testData.head())\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 842.38it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "      x1  x2  x3  x4        x5\n",
      "0      0   0   0   0  0.000000\n",
      "1      0   0   0   0  0.000000\n",
      "2      2   0   2   0  0.011152\n",
      "3      2   0   2   0  0.003670\n",
      "4      0   0   0   0  0.000000\n",
      "...   ..  ..  ..  ..       ...\n",
      "1995   0   0   0   0  0.000000\n",
      "1996   0   0   1   0  0.006061\n",
      "1997   0   0   0   0  0.000000\n",
      "1998   0   0   0   0  0.000000\n",
      "1999   0   0   0   0  0.000000\n",
      "\n",
      "[2000 rows x 5 columns]\n",
      "(2000, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_features = []\n",
    "\n",
    "for i in tqdm(range(len(test_source_list))) :\n",
    "    source = test_source_list[i]\n",
    "    sink = test_sink_list[i]\n",
    "    \n",
    "    x1, x2, x3, x4, x5 = gen_common_friends(source, sink, following_list, followers_list)\n",
    "    #feat2 = gen_node_stats(source, sink, following_numb, followers_numb)\n",
    "    \n",
    "    test_features.append([x1, x2, x3, x4, x5])\n",
    "    \n",
    "print(len(test_features))\n",
    "\n",
    "test_features = pd.DataFrame(test_features, columns = ['x1', 'x2', 'x3', 'x4', 'x5'])\n",
    "print(test_features)\n",
    "print(test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. New Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = test_features\n",
    "y_new = model.predict_proba(X_new)\n",
    "prob_link = [prob[1] for prob in y_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         Id  Predicted\n",
       "0        1   0.232822\n",
       "1        2   0.232822\n",
       "2        3   0.536230\n",
       "3        4   0.582011\n",
       "4        5   0.232822\n",
       "...    ...        ...\n",
       "1995  1996   0.232822\n",
       "1996  1997   0.259573\n",
       "1997  1998   0.232822\n",
       "1998  1999   0.232822\n",
       "1999  2000   0.232822\n",
       "\n",
       "[2000 rows x 2 columns]>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({'Id': testData_ids, 'Predicted': prob_link})\n",
    "output.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('output_v3-common-friends-noJC.csv', sep=\",\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
