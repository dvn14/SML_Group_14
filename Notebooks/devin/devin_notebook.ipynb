{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Devin's Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from random import choice, sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [00:31<00:00, 640.24it/s] \n"
     ]
    }
   ],
   "source": [
    "with open(\"train.txt\") as file :\n",
    "    all_lines = file.read().splitlines()\n",
    "\n",
    "followers = Counter()\n",
    "following = Counter()\n",
    "edges = defaultdict(list)\n",
    "all_nodes = []\n",
    "source_nodes = []\n",
    "\n",
    "for line in tqdm(all_lines) :\n",
    "    nodes = line.split(\"\\t\")\n",
    "    source, sinks = nodes[0], nodes[1:]\n",
    "    sinks = list(map(int, sinks))\n",
    "    source = int(source)\n",
    "    while source in sinks: sinks.remove(source)\n",
    "        \n",
    "    edges[source] = sinks\n",
    "    following[source] = len(sinks)\n",
    "    for sink in sinks :\n",
    "        followers[sink] += 1\n",
    "    \n",
    "    all_nodes.append(source)\n",
    "    all_nodes.extend(sinks)\n",
    "    source_nodes.append(source)\n",
    "    \n",
    "all_nodes = list(set(all_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats about `train.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines in train.txt:  20000\n",
      "Total edges in train.txt:  24004344\n",
      "Total distinct nodes 4867136\n",
      "Size of Source nodes:  20000\n",
      "Size of null entries:  430\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "null = 0\n",
    "\n",
    "for node in following :\n",
    "    if following[node] == 0 :\n",
    "        null += 1\n",
    "    else :\n",
    "        i += following[node]\n",
    "\n",
    "print(\"Total lines in train.txt: \", len(all_lines))\n",
    "print(\"Total edges in train.txt: \", i)\n",
    "print(\"Total distinct nodes\", len(all_nodes))\n",
    "print(\"Size of Source nodes: \", len(set(source_nodes)))\n",
    "print(\"Size of null entries: \", null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "testData_nodes = list(testData['Source'])\n",
    "testData_nodes.extend(list(testData['Sink']))\n",
    "testData_nodes = set(testData_nodes)\n",
    "print(len(testData_nodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Analysis\n",
    "\n",
    "Checking if all nodes in the test set (source and sink) appear in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source nodes on the test set was in source(train): 2000 ; sinks(train): 0\n",
      "Sink nodes on the test set was in source(train): 376 ; sinks(train): 1624\n"
     ]
    }
   ],
   "source": [
    "# i = 0; j = 0;\n",
    "# for node in testData['Source'] :\n",
    "#     if node in source_nodes :\n",
    "#         i += 1\n",
    "#     elif node in all_nodes :\n",
    "#         j += 1\n",
    "\n",
    "# print(\"Source nodes on the test set was in source(train):\", i, \"; sinks(train):\", j)\n",
    "\n",
    "# i = 0; j = 0;\n",
    "# for node in testData['Sink'] :\n",
    "#     if node in source_nodes :\n",
    "#         i += 1\n",
    "#     elif node in all_nodes :\n",
    "#         j += 1\n",
    "        \n",
    "# print(\"Sink nodes on the test set was in source(train):\", i, \"; sinks(train):\", j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Checking if sink node exist in source node's sinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 18), (52, 15), (34, 14), (39, 12), (23, 12), (6, 12), (24, 12), (68, 12), (26, 11), (2, 11)]\n"
     ]
    }
   ],
   "source": [
    "# j = []\n",
    "# for i, source in enumerate(testData['Source']) :\n",
    "#     j.append(len(edges[source]))\n",
    "\n",
    "# print(collections.Counter(j).most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preparing Data for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Positive Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list_1 = []\n",
    "node_list_2 = []\n",
    "\n",
    "for source in edges :\n",
    "    for sink in edges[source] :\n",
    "        node_list_1.append(source)\n",
    "        node_list_2.append(sink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Negative Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_edges = defaultdict(list)\n",
    "\n",
    "for source in edges :\n",
    "    while len(neg_edges[source]) < 200:\n",
    "        sink = choice(all_nodes)\n",
    "        if (sink not in edges[source] and sink not in neg_edges[source] and sink != source) :\n",
    "            neg_edges[source].append(sink)\n",
    "              \n",
    "neg_node_list_1 = []\n",
    "neg_node_list_2 = []\n",
    "\n",
    "for source in neg_edges :\n",
    "    for sink in neg_edges[source] :\n",
    "        neg_node_list_1.append(source)\n",
    "        neg_node_list_2.append(sink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "***\n",
    "**WARNING: TAKES 4 HOURS**\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3948/3948 [3:26:20<00:00,  3.14s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4697704\n",
      "[19062765, 19062766, 19062767, 19062768, 19062769, 19062770, 19062771, 19062772, 19062773]\n",
      "434262\n",
      "[748342, 1063577, 1268103, 1872727, 1920705, 2136447, 2159034, 3139726, 3379748]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# k = []\n",
    "# j = []\n",
    "\n",
    "# for node in tqdm(testData_nodes, total=len(testData_nodes)) :\n",
    "#     tmp_k = [i for i, value in enumerate(node_list_1) if value == node]\n",
    "#     k.extend(tmp_k)\n",
    "    \n",
    "#     tmp_j = [i for i, value in enumerate(node_list_2) if value == node]\n",
    "#     j.extend(tmp_j)\n",
    "    \n",
    "# print(len(k))\n",
    "# print(k[0:9])\n",
    "# print(len(j))\n",
    "# print(j[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-51865dd70b01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnewkj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnewj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnewkj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mindexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewkj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "# newkj = k.copy()\n",
    "# newj = j.copy()\n",
    "# newkj.extend(newj)\n",
    "# indexes = list(set(newkj))\n",
    "# indexes.sort()\n",
    "# print(len(indexes), min(indexes), max(indexes), sum(indexes)/len(indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Source     Sink\n",
      "0          540762  1912140\n",
      "1          540762  1537559\n",
      "2          540762  3091331\n",
      "3          540762  2757277\n",
      "4          540762  3237295\n",
      "...           ...      ...\n",
      "24004339  3547024  1075576\n",
      "24004340  3547024  4549841\n",
      "24004341  3547024  1135647\n",
      "24004342  3547024   807274\n",
      "24004343  3547024  3897045\n",
      "\n",
      "[5053079 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# \"\"\"\n",
    "# x1 = []\n",
    "# x2 = []\n",
    "# x3 = []\n",
    "# x4 = []\n",
    "\n",
    "# for node in tqdm(node_list_1, total=len(node_list_1)):\n",
    "#     x1.append(nfollowing(row['Source'], edges))\n",
    "#     x3.append(nfollowers(row['Source'], edges))\n",
    "    \n",
    "# for node in tqdm(node_list_2, total=len(node_list_2)):\n",
    "#     x2.append(nfollowing(row['Sink'], edges))\n",
    "#     x4.append(nfollowers(row['Sink'], edges))\n",
    "# \"\"\"\n",
    "# trainData = pd.DataFrame({'Source': node_list_1, 'Sink': node_list_2})\n",
    "# trainData_reduced = trainData.iloc[indexes,:]\n",
    "# trainData_reduced = trainData_reduced.drop_duplicates()\n",
    "# print(trainData_reduced)\n",
    "# trainData_reduced.to_csv('trainData_reduced.txt', sep=\"\\t\", index=True, header=True, index_label = \"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  Source     Sink\n",
      "0   0  540762  1912140\n",
      "1   1  540762  1537559\n",
      "2   2  540762  3091331\n",
      "3   3  540762  2757277\n",
      "4   4  540762  3237295\n",
      "(5053079, 3)\n"
     ]
    }
   ],
   "source": [
    "# trainData_reduced = pd.read_csv('trainData_reduced.txt', sep=\"\\t\")\n",
    "# print(trainData_reduced.head())\n",
    "# print(trainData_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature Engineering\n",
    "\n",
    "- **x1** - Number following (Source).\n",
    "- **x2** - Number following (Sink).\n",
    "- **x3** - Number of followers (Source).\n",
    "- **x4** - Number of followers (Sink).\n",
    "- **x5** - Common nodes - following (Source and sink)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features (source_list, sink_list, following, followers, target=None) :\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    x3 = []\n",
    "    x4 = []\n",
    "    x5 = []\n",
    "    \n",
    "    for i in tqdm(range(len(source_list))) :\n",
    "        source = source_list[i]\n",
    "        sink = sink_list[i]\n",
    "        x1.append(following[source])\n",
    "        x2.append(following[sink])\n",
    "        x3.append(followers[source])\n",
    "        x4.append(followers[sink])\n",
    "    \n",
    "    if target is not None :\n",
    "        df = pd.DataFrame({'Source': source_list, 'Sink': sink_list, 'x1': x1, 'x2': x2, 'x3': x3, 'x4': x4, 'Target': target})\n",
    "    else :\n",
    "        df = pd.DataFrame({'Source': source_list, 'Sink': sink_list, 'x1': x1, 'x2': x2, 'x3': x3, 'x4': x4})\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24004344/24004344 [00:46<00:00, 520948.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Source     Sink   x1   x2   x3   x4  Target\n",
      "0  540762  1912140  143   20  142   37       1\n",
      "1  540762  1537559  143   79  142   76       1\n",
      "2  540762  3091331  143   26  142   28       1\n",
      "3  540762  2757277  143  222  142  107       1\n",
      "4  540762  3237295  143  119  142   57       1\n",
      "(24004344, 7)\n"
     ]
    }
   ],
   "source": [
    "pos_trainData = generate_features(node_list_1, node_list_2, following, followers, 1)\n",
    "print(pos_trainData.head())\n",
    "print(pos_trainData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000000/4000000 [00:08<00:00, 493742.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Source     Sink   x1  x2   x3  x4  Target\n",
      "0  540762  3798563  143   0  142   1       0\n",
      "1  540762  2024044  143   0  142   2       0\n",
      "2  540762  2256179  143   0  142   6       0\n",
      "3  540762  3133206  143  14  142   3       0\n",
      "4  540762   877004  143   0  142   2       0\n",
      "(4000000, 7)\n"
     ]
    }
   ],
   "source": [
    "neg_trainData = generate_features(neg_node_list_1, neg_node_list_2, following, followers, 0)\n",
    "print(neg_trainData.head())\n",
    "print(neg_trainData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    x1   x2   x3   x4\n",
      "0  143   20  142   37\n",
      "1  143   79  142   76\n",
      "2  143   26  142   28\n",
      "3  143  222  142  107\n",
      "4  143  119  142   57\n",
      "(28004344, 4)\n",
      "   Target\n",
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "(28004344, 1)\n"
     ]
    }
   ],
   "source": [
    "trainData_full = pd.concat([pos_trainData, neg_trainData], ignore_index=True)\n",
    "trainData_features = trainData_full[['x1', 'x2', 'x3', 'x4']]\n",
    "trainData_response = trainData_full[['Target']]\n",
    "print(trainData_features.head())\n",
    "print(trainData_features.shape)\n",
    "\n",
    "print(trainData_response.head())\n",
    "print(trainData_response.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    np.asarray(y_true)\n",
    "    np.asarray(y_pred)\n",
    "    return np.mean((y_pred - y_true)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 22403475 instances. Test set has 5600869 instances.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainData_features, trainData_response, test_size=0.2, random_state=90051)\n",
    "print(\"Training set has {} instances. Test set has {} instances.\".format(X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: Target    0.109942\n",
      "dtype: float64\n",
      "Test MSE: Target    0.110046\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression().fit(X_train, y_train)\n",
    "y_pred_train = lin_reg.predict(X_train)\n",
    "y_pred_test = lin_reg.predict(X_test)\n",
    "\n",
    "print('Train MSE:', mean_squared_error(y_pred_train, y_train))\n",
    "print('Test MSE:', mean_squared_error(y_pred_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Loading Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   Source     Sink\n",
      "0   1  3563811  3600160\n",
      "1   2  2052043  1401960\n",
      "2   3  4517994  1690636\n",
      "3   4  1660006  4349447\n",
      "4   5   581111  1882617\n",
      "(2000, 3)\n"
     ]
    }
   ],
   "source": [
    "testData = pd.read_csv('test-public.txt', sep=\"\\t\")\n",
    "testData_ids = list(testData['Id'])\n",
    "print(testData.head())\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 20673.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Source     Sink   x1  x2  x3  x4\n",
      "0  3563811  3600160   21   0   3  29\n",
      "1  2052043  1401960   71   0  13   9\n",
      "2  4517994  1690636  205   0  80  17\n",
      "3  1660006  4349447  506   0  32  36\n",
      "4   581111  1882617   18   0   5  46\n",
      "(2000, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "testData_features = generate_features(list(testData['Source']), list(testData['Sink']), following, followers, None)\n",
    "print(testData_features.head())\n",
    "print(testData_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. New Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = testData_features[['x1', 'x2', 'x3', 'x4']]\n",
    "y_new = lin_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         Id  Predicted\n",
       "0        1   0.766499\n",
       "1        2   0.762016\n",
       "2        3   0.772171\n",
       "3        4   0.771837\n",
       "4        5   0.771544\n",
       "...    ...        ...\n",
       "1995  1996   0.760392\n",
       "1996  1997   0.775787\n",
       "1997  1998   0.759215\n",
       "1998  1999   0.759612\n",
       "1999  2000   0.759658\n",
       "\n",
       "[2000 rows x 2 columns]>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({'Id': testData_ids, 'Predicted': y_new.flatten()})\n",
    "output.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('output.csv', sep=\",\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
